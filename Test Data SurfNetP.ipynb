{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d94db0-d75f-46c2-855f-c81da6749f7e",
   "metadata": {},
   "source": [
    "## Info about training data:\n",
    "\n",
    "\n",
    "Raw data is given in Numpy compressed file with an array of pdb chain ids (pdbids) and a 3 dimensional array of input output features:\n",
    "- 1st dimension: samples\n",
    "- 2nd dimension: sequence position\n",
    "- 3rd dimension: input features\n",
    "\n",
    "[0:20] Amino Acids (sparse encoding)\n",
    "\n",
    "Unknown residues are stored as an all-zero vector\n",
    "\n",
    "[20:50] hmm profile\n",
    "\n",
    "[50] Seq mask (1 = seq, 0 = empty)\n",
    "\n",
    "[51] Disordered mask (0 = disordered, 1 = ordered)\n",
    "\n",
    "[52] Evaluation mask (For CB513 dataset, 1 = eval, 0 = ignore)\n",
    "[53] ASA (isolated)\n",
    "\n",
    "[54] ASA (complexed)\n",
    "\n",
    "[55] RSA (isolated)\n",
    "\n",
    "[56] RSA (complexed)\n",
    "\n",
    "[57:65] Q8 GHIBESTC (Q8 -> Q3: HHHEECCC)\n",
    "\n",
    "[65:67] Phi+Psi\n",
    "\n",
    "[67] ASA_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27e5fc3-4f98-41f2-8c6c-33af53ba52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc8be197-898c-4d6e-86a3-7aa1fc1a95fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load('Train_MMseqs.npz', allow_pickle=True)\n",
    "lst = data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3fd92f-491b-429e-89b9-e9619c8f8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "letters = [\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"Y\"]\n",
    "\n",
    "def Prep_data(Subset_name,Subset_points):\n",
    "    Sequences = []\n",
    "    ASA_i = []\n",
    "\n",
    "    for i in range(len(Subset_name)):\n",
    "        Seq = Subset_points[i]\n",
    "        index = \"\"\n",
    "        for j in range(100):\n",
    "            try:\n",
    "                index += str((letters[np.where(Seq[j,0:20] == 1)[0][0]])) + \" \"\n",
    "            except:\n",
    "                    index += \"X\" + \" \"\n",
    "\n",
    "        t = torch.tensor(Subset_points[i][0:100,54])\n",
    "        ASA_i.append(t.unsqueeze(-1)) \n",
    "        Sequences.append(index)\n",
    "        \n",
    "    d = {\"Subset_name\" : Subset_name,\"Sequence\" : Sequences}\n",
    "    df = pd.DataFrame(data = d)\n",
    "    \n",
    "    return df,ASA_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daff9938-a169-440e-9e22-c5ac90a35412",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     Rands \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m10848\u001b[39m,size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m);\n\u001b[0;32m      7\u001b[0m     Subset_name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data[lst[\u001b[38;5;241m0\u001b[39m]][Rands])\n\u001b[1;32m----> 8\u001b[0m     Subset_points \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlst\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[Rands])\n\u001b[0;32m     10\u001b[0m Subset_name \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Subset_name)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:254\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py:779\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[0;32m    778\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[1;32m--> 779\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    781\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py:908\u001b[0m, in \u001b[0;36m_read_bytes\u001b[1;34m(fp, size, error_template)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 908\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    909\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:924\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 924\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:1014\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1014\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_crc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:939\u001b[0m, in \u001b[0;36mZipExtFile._update_crc\u001b[1;34m(self, newdata)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 939\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m=\u001b[39m \u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_running_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# subset\n",
    "Subset_name = []\n",
    "Subset_points = []\n",
    "\n",
    "for i in range(10):\n",
    "    Rands = np.random.randint(10848,size=50);\n",
    "    Subset_name += list(data[lst[0]][Rands])\n",
    "    Subset_points += list(data[lst[1]][Rands])\n",
    "\n",
    "Subset_name = np.array(Subset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e34a61-682f-4cca-925d-b74ee0091d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subset_name</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2wp7-A</td>\n",
       "      <td>M E P P N L Y P V K L Y V Y D L S K G L A R R ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ayn-A</td>\n",
       "      <td>M K V Q S L L R I E T Q L L L G R L L T R S G ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4r0s-B</td>\n",
       "      <td>M H R S P L A W L R L L L A A V L G A F L L G ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1c0a-A</td>\n",
       "      <td>M R T E Y C G Q L R L S H V G Q Q V T L C G W ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4jzp-B</td>\n",
       "      <td>S X L D V G N A E V K L E E E N R S L K A D L ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subset_name                                           Sequence\n",
       "0      2wp7-A  M E P P N L Y P V K L Y V Y D L S K G L A R R ...\n",
       "1      5ayn-A  M K V Q S L L R I E T Q L L L G R L L T R S G ...\n",
       "2      4r0s-B  M H R S P L A W L R L L L A A V L G A F L L G ...\n",
       "3      1c0a-A  M R T E Y C G Q L R L S H V G Q Q V T L C G W ...\n",
       "4      4jzp-B  S X L D V G N A E V K L E E E N R S L K A D L ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train,targs_train = Prep_data(Subset_name,Subset_points)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be320d7-96c9-45b4-82c8-401c47d6a453",
   "metadata": {},
   "source": [
    "Now the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a3e4f1-6085-4c4a-9660-ad38439405c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Subset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef557d65-45e4-4743-b6b2-205c763b2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_excel(\"500_train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee38eb3-4d1a-42cd-b556-f5db2bbc02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = load('CASP12_MMseqs.npz', allow_pickle=True)\n",
    "lst = data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d15f3c9-bfb3-4b22-bbc8-bb80a8387c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_name_test = []\n",
    "Subset_points_test = []\n",
    "\n",
    "for i in range(len(data_test[lst[0]])):\n",
    "    Subset_name_test.append(data_test[lst[0]][i])\n",
    "    Subset_points_test.append(data_test[lst[1]][i])\n",
    "\n",
    "Subset_name_test = np.array(Subset_name_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5260b6-8a4d-4c92-bac9-56c635ce03cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subset_name</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a7d-L</td>\n",
       "      <td>S L R F T A S T S T P K S G S K I A K R G K K ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5aot-A</td>\n",
       "      <td>M G A E E E D T A I L Y P F T I S G N D R N G ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d9g-A</td>\n",
       "      <td>G H X A S G P W K L T A S K T H I X K S A D V ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fhy-A</td>\n",
       "      <td>M G H H H H H H G G S E N L Y F Q G N E D I L ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5g5n-A</td>\n",
       "      <td>G L P V P S P P G T L L P G Q S P D E A F A R ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subset_name                                           Sequence\n",
       "0      5a7d-L  S L R F T A S T S T P K S G S K I A K R G K K ...\n",
       "1      5aot-A  M G A E E E D T A I L Y P F T I S G N D R N G ...\n",
       "2      5d9g-A  G H X A S G P W K L T A S K T H I X K S A D V ...\n",
       "3      5fhy-A  M G H H H H H H G G S E N L Y F Q G N E D I L ...\n",
       "4      5g5n-A  G L P V P S P P G T L L P G Q S P D E A F A R ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test,targs_test = Prep_data(Subset_name_test,Subset_points_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ab80fa-9379-4a93-b03a-98306fe2e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_excel(\"CASP12_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2c58dae-1f44-4f8d-b791-9d94a8700a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targ = torch.concat(targs_train[:-50],1)\n",
    "valid_targ = torch.concat(targs_train[-50:],1)\n",
    "test_targ = torch.concat(targs_test,1)\n",
    "\n",
    "# list of concatenated targets (ASA_i)\n",
    "targ_all = [train_targ,valid_targ,test_targ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40307f66-8279-4ac2-b6c4-59133cf5aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(targ_all,\"targs_ASA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370ee1bf-a796-4b17-acfa-9c0446d1a946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Device: <span style=\"color: #800000; text-decoration-color: #800000\">cpu</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Device: \u001b[31mcpu\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip install ipywidgets rich seaborn torch datasets transformers tokenizers sentencepiece sacremoses --quiet\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import rich\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import tokenizers\n",
    "import datasets\n",
    "import zipfile\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# define the device to use\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "rich.print(f\"Device: [red]{DEVICE}\")\n",
    "\n",
    "# control verbosity\n",
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57bcf189-6f91-4b53-8dc4-3e453fd3acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import re\n",
    "tokenizer = BertTokenizer.from_pretrained('Rostlab/prot_bert_bfd', do_lower_case=False)\n",
    "model_embedder = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d1b193-0a55-47ae-8f21-e22d1ed28161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"500_train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b8602c-f94f-497f-8ee5-530f73654794",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86775afa-b9f7-4b43-b48d-53560a07b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in range(450,500):\n",
    "    sequence_train = df_train[\"Sequence\"][seq]\n",
    "    encoded_input = tokenizer(sequence_train, return_tensors='pt')\n",
    "    output = model_embedder(**encoded_input)\n",
    "    t_data.append(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c93e557-39dd-4681-9ca6-c5ce4d5d1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_seq in range(len(df_test)):\n",
    "    sequence_test = df_test[\"Sequence\"][test_seq]\n",
    "    encoded_input = tokenizer(sequence_test, return_tensors='pt')\n",
    "    output = model_embedder(**encoded_input)\n",
    "    test_data.append(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b10e9789-7db8-453d-a700-cf5ba933687a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd98595-efb0-4b59-ba5f-4431248ace89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Old = torch.load('0_450_embedded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023f4d72-3f6c-401f-9804-1d54361e9a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([450, 102, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1188a660-9b4c-4e1d-8673-3e993c1a0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "New = torch.concat(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e95055-c6bd-40df-aa34-0940aef099f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 102, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((Old,New),0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a35d830c-085b-4bf6-b5da-749e771c02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final = torch.cat((Old,New),0)\n",
    "torch.save(Final,\"0_500_embedded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5952980f-9c76-4845-a212-090c9862ad41",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concat(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat(t_data[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      2\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat(t_data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m:])\n\u001b[1;32m----> 3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# list of all embeddings for the train, valid and test.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m data_embedded \u001b[38;5;241m=\u001b[39m [train_data,valid_data,test_data]\n",
      "\u001b[1;31mTypeError\u001b[0m: concat(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "train_data = torch.concat(t_data[:-5])\n",
    "valid_data = torch.concat(t_data[-5:])\n",
    "test_data = torch.concat(test_data)\n",
    "\n",
    "# list of all embeddings for the train, valid and test.\n",
    "data_embedded = [train_data,valid_data,test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee6884b9-0f0b-4f7e-badb-7d280772fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving them.\n",
    "df_train.to_excel(\"df_train.xlsx\")\n",
    "torch.save(data_embedded,'data_embedded')\n",
    "torch.save(targ_all,\"targs_ASA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
